{
    "Title": "Convolutional Variational AutoEncoder - MNIST",
    "Tags": ["VAE","MNIST"],
    "Architecture": "VAE",
    "Publisher": [["Tanmay Thakur","https://github.com/lordtt13"], ["Smoketrees","https://github.com/smoke-trees"]],
    "Problem Domain": "Image",
    "Model Format": "Tensorflow2",
    "Language": "null",
    "Dataset": [["MNIST","http://yann.lecun.com/exdb/mnist/"]],
    "Overview": "A VAE made from the MNIST dataset, with ELBO losses",
    "Preprocessing": "null",
    "Link": "https://drive.google.com/file/d/1m9GBIgwOUxlBhlLqYUNDyEfb5NmP7VXt/view?usp=sharing",
    "Usage": "usage.html",
    "References": ["https://arxiv.org/abs/1906.02691"],
    "Input Shape": [[1,50]],
    "Output Shape": [[28,28,1]],
    "Description": "Convolutional Variational Auto-Encoder for MNIST : A VAE is a probabilistic take on the autoencoder, a model which takes high dimensional input data compress it into a smaller representation. Unlike a traditional autoencoder, which maps the input onto a latent vector, a VAE maps the input data into the parameters of a probability distribution, such as the mean and variance of a Gaussian. This approach produces a continuous, structured latent space, which is useful for image generation. Each MNIST image is originally a vector of 784 integers, each of which is between 0-255 and represents the intensity of a pixel. We model each pixel with a Bernoulli distribution in our model, and we statically binarize the dataset. For the encoder network, we use a two convolutional layers dense layer followed by fully connected layer. In the decoder network, we mirror this architecture by using a fully-connected layer followed by three convolution transpose layers (a.k.a. deconvolutional layers in some contexts)."
}
